# äº‘å¹³å°RTX 5090è¿è¡Œå®Œæ•´Demoæ–¹æ¡ˆ

## ðŸ“‹ ç›®å½•

1. [çŽ¯å¢ƒå‡†å¤‡](#çŽ¯å¢ƒå‡†å¤‡)
2. [å¿«é€Ÿéƒ¨ç½²](#å¿«é€Ÿéƒ¨ç½²)
3. [å®Œæ•´Demoè¿è¡Œ](#å®Œæ•´demoè¿è¡Œ)
4. [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#æ€§èƒ½ä¼˜åŒ–å»ºè®®)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ðŸš€ çŽ¯å¢ƒå‡†å¤‡

### 1. äº‘å¹³å°è§„æ ¼æŽ¨è

**æŽ¨èé…ç½®**ï¼ˆRTX 5090ï¼‰ï¼š
```
GPU:     NVIDIA RTX 5090 (24GB VRAM)
CPU:     16æ ¸å¿ƒä»¥ä¸Š
å†…å­˜:    32GB+
å­˜å‚¨:    100GB+ SSD
ç³»ç»Ÿ:    Ubuntu 20.04/22.04 LTS
CUDA:    12.1+
```

**æ”¯æŒçš„äº‘å¹³å°**ï¼š
- AutoDL (æŽ¨èï¼Œæ€§ä»·æ¯”é«˜)
- æ’æºäº‘
- çŸ©æ± äº‘
- AWS EC2 (g5/p4 å®žä¾‹)
- Google Cloud (A100/V100)
- é˜¿é‡Œäº‘PAI-DSW

### 2. ç³»ç»ŸçŽ¯å¢ƒæ£€æŸ¥

ç™»å½•äº‘å¹³å°åŽï¼Œé¦–å…ˆæ£€æŸ¥GPUçŠ¶æ€ï¼š

```bash
# æ£€æŸ¥GPU
nvidia-smi

# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
uname -a
cat /etc/os-release
```

---

## ðŸŽ¯ å¿«é€Ÿéƒ¨ç½²

### æ–¹æ¡ˆAï¼šä¸€é”®éƒ¨ç½²è„šæœ¬ï¼ˆæŽ¨èï¼‰

åˆ›å»ºéƒ¨ç½²è„šæœ¬ `deploy_cloud.sh`ï¼š

```bash
#!/bin/bash
# RTX 5090äº‘å¹³å°å¿«é€Ÿéƒ¨ç½²è„šæœ¬

set -e

echo "=================================================="
echo "Stock Prediction System - Cloud GPU Deployment"
echo "GPU: NVIDIA RTX 5090"
echo "=================================================="
echo ""

# 1. å…‹éš†é¡¹ç›®
echo "Step 1: Cloning repository..."
git clone https://github.com/li147852xu/ARIN7101_Project_Stock_Prediction.git
cd ARIN7101_Project_Stock_Prediction

# 2. åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
echo ""
echo "Step 2: Creating virtual environment..."
python3 -m venv venv
source venv/bin/activate

# 3. å‡çº§pip
echo ""
echo "Step 3: Upgrading pip..."
pip install --upgrade pip

# 4. å®‰è£…PyTorch (CUDA 12.1)
echo ""
echo "Step 4: Installing PyTorch with CUDA support..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 5. å®‰è£…å…¶ä»–ä¾èµ–
echo ""
echo "Step 5: Installing other dependencies..."
pip install -r requirements.txt

# 6. å®‰è£…å¯é€‰ä¾èµ–
echo ""
echo "Step 6: Installing optional dependencies..."
pip install yfinance akshare ta prophet statsmodels

# 7. å°è¯•å®‰è£…Mambaï¼ˆå¯é€‰ï¼‰
echo ""
echo "Step 7: Installing Mamba (optional, may fail)..."
pip install mamba-ssm causal-conv1d || echo "Mamba installation skipped, will use GRU fallback"

# 8. éªŒè¯å®‰è£…
echo ""
echo "Step 8: Verifying installation..."
python test_setup.py

# 9. æµ‹è¯•GPU
echo ""
echo "Step 9: Testing GPU availability..."
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"

echo ""
echo "=================================================="
echo "Deployment completed successfully!"
echo "Run demo with: python main.py"
echo "=================================================="
```

è¿è¡Œéƒ¨ç½²ï¼š

```bash
# ä¸‹è½½å¹¶è¿è¡Œéƒ¨ç½²è„šæœ¬
wget https://raw.githubusercontent.com/li147852xu/ARIN7101_Project_Stock_Prediction/main/deploy_cloud.sh
chmod +x deploy_cloud.sh
./deploy_cloud.sh
```

### æ–¹æ¡ˆBï¼šæ‰‹åŠ¨éƒ¨ç½²ï¼ˆæ›´å¯æŽ§ï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/li147852xu/ARIN7101_Project_Stock_Prediction.git
cd ARIN7101_Project_Stock_Prediction

# 2. åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 3. å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# 5. æµ‹è¯•é…ç½®
python test_setup.py
```

---

## ðŸŽ¬ å®Œæ•´Demoè¿è¡Œ

### Demo 1: å¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šéªŒè¯çŽ¯å¢ƒï¼Œå¿«é€Ÿæµ‹è¯•

```bash
# ä¿®æ”¹é…ç½®ä»¥åŠ é€Ÿ
cat > config_quick.yaml << 'EOF'
data:
  stock_codes:
    - "600519.SS"  # ä»…æµ‹è¯•1åªè‚¡ç¥¨
  start_date: "2023-01-01"
  end_date: null
  data_source: "yfinance"
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"

features:
  sequence_length: 20  # å‡å°‘åºåˆ—é•¿åº¦
  prediction_horizon: 1
  indicators:
    ma_periods: [5, 10, 20]  # å‡å°‘æŒ‡æ ‡
    macd_fast: 12
    macd_slow: 26
    macd_signal: 9
    rsi_period: 14
    bb_period: 20
    bb_std: 2
    atr_period: 14
    stoch_period: 14
    cci_period: 20
    williams_period: 14
    roc_period: 10
    mfi_period: 14

dataset:
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15

models:
  mlp:
    hidden_dims: [64, 32]  # å‡å°æ¨¡åž‹
    dropout: 0.3
    activation: "relu"
  
  lstm:
    hidden_dim: 64
    num_layers: 2
    dropout: 0.3
    bidirectional: true

training:
  batch_size: 128  # å¢žå¤§batch
  epochs: 10       # å‡å°‘epochs
  learning_rate: 0.001
  optimizer: "adam"
  scheduler:
    type: "reduce_on_plateau"
    patience: 5
    factor: 0.5
  early_stopping:
    patience: 10
    min_delta: 0.001
  loss: "cross_entropy"
  use_class_weights: true
  seed: 42
  device: "cuda"

evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "auc"
  save_confusion_matrix: true
  save_roc_curve: true
  results_dir: "results"

visualization:
  enable: true
  plots_dir: "plots"
  format: "png"
  dpi: 150

logging:
  level: "INFO"
  log_dir: "logs"
  save_to_file: true
EOF

# è¿è¡Œå¿«é€Ÿæµ‹è¯•
python main.py --config config_quick.yaml --step train --model mlp,lstm
```

**é¢„æœŸæ—¶é—´**ï¼š3-5åˆ†é’Ÿ

### Demo 2: æ ‡å‡†Demoï¼ˆ20åˆ†é’Ÿï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå®Œæ•´å±•ç¤ºï¼Œä¸­ç­‰è§„æ¨¡

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œé€‰æ‹©éƒ¨åˆ†æ¨¡åž‹
python main.py --step download  # ä¸‹è½½æ•°æ® (~2åˆ†é’Ÿ)
python main.py --step train --model mlp,lstm,transformer  # è®­ç»ƒ (~15åˆ†é’Ÿ)
python main.py --step evaluate  # è¯„ä¼° (~3åˆ†é’Ÿ)
```

**é¢„æœŸç»“æžœ**ï¼š
- è®­ç»ƒ3ä¸ªæ·±åº¦å­¦ä¹ æ¨¡åž‹
- ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š
- å¯è§†åŒ–å›¾è¡¨

### Demo 3: å®Œæ•´Demoï¼ˆ60-90åˆ†é’Ÿï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå®Œæ•´å®žéªŒï¼Œæ‰€æœ‰æ¨¡åž‹å¯¹æ¯”

#### 3.1 ä¿®æ”¹é…ç½®ä»¥å……åˆ†åˆ©ç”¨GPU

ç¼–è¾‘ `config.yaml`ï¼š

```yaml
training:
  batch_size: 256      # RTX 5090å¯ä»¥ä½¿ç”¨æ›´å¤§batch
  epochs: 50           # å……åˆ†è®­ç»ƒ
  device: "cuda"

data:
  stock_codes:
    - "600519.SS"
    - "600036.SS"
    - "601318.SS"
    - "600030.SS"
    - "600887.SS"
```

#### 3.2 è¿è¡Œå®Œæ•´æµç¨‹

```bash
# æ–¹å¼1: ä¸€æ¬¡æ€§è¿è¡Œæ‰€æœ‰
python main.py

# æ–¹å¼2: åˆ†æ­¥è¿è¡Œï¼ˆæŽ¨èï¼Œä¾¿äºŽç›‘æŽ§ï¼‰
# Step 1: ä¸‹è½½å’Œå¤„ç†æ•°æ®
python main.py --step download

# Step 2: è®­ç»ƒæ‰€æœ‰æ·±åº¦å­¦ä¹ æ¨¡åž‹
python main.py --step train --model mlp,lstm,transformer,mamba

# Step 3: è¯„ä¼°æ‰€æœ‰æ¨¡åž‹
python main.py --step evaluate

# Step 4: å¦‚æžœéœ€è¦ï¼Œè®­ç»ƒç»Ÿè®¡æ¨¡åž‹
# æ³¨æ„ï¼šARIMAå’ŒProphetè¾ƒæ…¢ï¼Œå¯ä»¥å•ç‹¬è¿è¡Œ
python main.py --step train --model arima
python main.py --step train --model prophet
```

#### 3.3 ç›‘æŽ§GPUä½¿ç”¨

åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£ï¼š

```bash
# å®žæ—¶ç›‘æŽ§GPU
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨æ›´è¯¦ç»†çš„ç›‘æŽ§
nvidia-smi dmon -s pucvmet
```

#### 3.4 é¢„æœŸè¾“å‡º

```
results/
â”œâ”€â”€ models/                          # è®­ç»ƒå¥½çš„æ¨¡åž‹
â”‚   â”œâ”€â”€ mlp.pth
â”‚   â”œâ”€â”€ lstm.pth
â”‚   â”œâ”€â”€ transformer.pth
â”‚   â””â”€â”€ mamba.pth
â”œâ”€â”€ model_comparison.csv             # æ¨¡åž‹å¯¹æ¯”è¡¨
â””â”€â”€ *_classification_report.txt      # å„æ¨¡åž‹è¯¦ç»†æŠ¥å‘Š

plots/
â”œâ”€â”€ model_comparison.png             # æ¨¡åž‹å¯¹æ¯”å›¾
â”œâ”€â”€ mlp_confusion_matrix.png         # æ··æ·†çŸ©é˜µ
â”œâ”€â”€ mlp_roc_curve.png               # ROCæ›²çº¿
â”œâ”€â”€ mlp_training_history.png        # è®­ç»ƒåŽ†å²
â””â”€â”€ ... (å…¶ä»–æ¨¡åž‹çš„å›¾è¡¨)

logs/
â””â”€â”€ *.log                            # è¿è¡Œæ—¥å¿—
```

---

## ðŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPUå†…å­˜ä¼˜åŒ–

```python
# å¦‚æžœé‡åˆ°OOM (Out of Memory)ï¼Œä¿®æ”¹config.yaml

training:
  batch_size: 128  # ä»Ž256é™ä½Žåˆ°128
  
models:
  lstm:
    hidden_dim: 96   # ä»Ž128é™ä½Ž
  
  transformer:
    d_model: 96      # ä»Ž128é™ä½Ž
    num_layers: 2    # ä»Ž3é™ä½Ž
```

### 2. æ•°æ®åŠ è½½ä¼˜åŒ–

```yaml
# å¯ç”¨æ•°æ®ç¼“å­˜
data:
  use_cache: true  # ç¬¬äºŒæ¬¡è¿è¡Œæ—¶ä¼šæ›´å¿«
  
features:
  sequence_length: 30  # ä¸è¦è®¾ç½®å¤ªé•¿
```

### 3. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆåŠ é€Ÿ2å€ï¼‰

åˆ›å»º `config_fp16.yaml`ï¼š

```yaml
training:
  use_amp: true      # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
  batch_size: 512    # å¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch
```

ç„¶åŽåœ¨ `src/train.py` ä¸­æ·»åŠ AMPæ”¯æŒï¼ˆå·²é¢„ç•™æŽ¥å£ï¼‰ã€‚

### 4. å¤šGPUè®­ç»ƒï¼ˆå¦‚æœ‰å¤šå¡ï¼‰

```bash
# ä½¿ç”¨DataParallel
export CUDA_VISIBLE_DEVICES=0,1
python main.py --config config_multigpu.yaml
```

### 5. å¹¶è¡Œæ•°æ®é¢„å¤„ç†

```yaml
# config.yaml
training:
  num_workers: 4  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
```

---

## ðŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### RTX 5090é¢„æœŸæ€§èƒ½

| æ¨¡åž‹ | Batch Size | è®­ç»ƒæ—¶é—´/Epoch | æŽ¨ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ |
|------|-----------|---------------|---------|---------|
| MLP | 256 | ~10ç§’ | 5000 samples/s | ~2GB |
| LSTM | 256 | ~30ç§’ | 2000 samples/s | ~4GB |
| Transformer | 256 | ~45ç§’ | 1500 samples/s | ~6GB |
| Mamba | 256 | ~35ç§’ | 2500 samples/s | ~5GB |

### å®Œæ•´Demoæ—¶é—´ä¼°ç®—

| æ­¥éª¤ | æ—¶é—´ | è¯´æ˜Ž |
|-----|------|-----|
| æ•°æ®ä¸‹è½½ | 2-5åˆ†é’Ÿ | å–å†³äºŽç½‘ç»œé€Ÿåº¦ |
| ç‰¹å¾è®¡ç®— | 1-2åˆ†é’Ÿ | 40+ä¸ªæŒ‡æ ‡ |
| MLPè®­ç»ƒ | 5-10åˆ†é’Ÿ | 50 epochs |
| LSTMè®­ç»ƒ | 15-20åˆ†é’Ÿ | 50 epochs |
| Transformerè®­ç»ƒ | 20-30åˆ†é’Ÿ | 50 epochs |
| Mambaè®­ç»ƒ | 15-25åˆ†é’Ÿ | 50 epochs |
| è¯„ä¼° | 2-3åˆ†é’Ÿ | æ‰€æœ‰æ¨¡åž‹ |
| **æ€»è®¡** | **60-90åˆ†é’Ÿ** | å®Œæ•´æµç¨‹ |

---

## ðŸŽ“ Demoæ¼”ç¤ºè„šæœ¬

### å®Œæ•´æ¼”ç¤ºæµç¨‹

```bash
#!/bin/bash
# demo_complete.sh - å®Œæ•´Demoæ¼”ç¤ºè„šæœ¬

echo "=================================================="
echo "Stock Price Prediction - Complete Demo"
echo "Platform: Cloud GPU (RTX 5090)"
echo "=================================================="
echo ""

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export PYTHONUNBUFFERED=1

# æ¿€æ´»çŽ¯å¢ƒ
source venv/bin/activate

echo "Step 1: Testing GPU..."
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}'); print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"

echo ""
echo "Step 2: Downloading data..."
python main.py --step download

echo ""
echo "Step 3: Training MLP (baseline)..."
python main.py --step train --model mlp

echo ""
echo "Step 4: Training LSTM..."
python main.py --step train --model lstm

echo ""
echo "Step 5: Training Transformer..."
python main.py --step train --model transformer

echo ""
echo "Step 6: Training Mamba..."
python main.py --step train --model mamba

echo ""
echo "Step 7: Evaluating all models..."
python main.py --step evaluate

echo ""
echo "=================================================="
echo "Demo completed!"
echo "Results saved to: results/"
echo "Plots saved to: plots/"
echo "=================================================="
echo ""
echo "Key results:"
cat results/model_comparison.csv

# æ˜¾ç¤ºå¯è§†åŒ–ï¼ˆå¦‚æžœæ”¯æŒX11è½¬å‘ï¼‰
if [ -n "$DISPLAY" ]; then
    echo ""
    echo "Opening result plots..."
    xdg-open plots/model_comparison.png
fi
```

è¿è¡ŒDemoï¼š

```bash
chmod +x demo_complete.sh
./demo_complete.sh
```

---

## ðŸ”§ å®žæ—¶ç›‘æŽ§æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: TensorBoardé›†æˆ

åˆ›å»º `tensorboard_monitor.py`ï¼š

```python
#!/usr/bin/env python
"""
TensorBoardç›‘æŽ§è„šæœ¬
"""
from torch.utils.tensorboard import SummaryWriter
import subprocess
import sys

def start_tensorboard():
    writer = SummaryWriter('runs/stock_prediction')
    print("TensorBoard started at: http://localhost:6006")
    subprocess.Popen(['tensorboard', '--logdir', 'runs', '--bind_all'])
    
if __name__ == '__main__':
    start_tensorboard()
```

è¿è¡Œï¼š

```bash
python tensorboard_monitor.py &
# è®¿é—®: http://[äº‘æœåŠ¡å™¨IP]:6006
```

### æ–¹æ¡ˆ2: å®žæ—¶æ—¥å¿—æŸ¥çœ‹

```bash
# åœ¨è®­ç»ƒçš„åŒæ—¶ï¼Œå¦å¼€ä¸€ä¸ªç»ˆç«¯
tail -f logs/*.log

# æˆ–ä½¿ç”¨æ›´å‹å¥½çš„å·¥å…·
pip install loguru
# ç„¶åŽæŸ¥çœ‹å½©è‰²æ—¥å¿—
```

### æ–¹æ¡ˆ3: GPUç›‘æŽ§è„šæœ¬

åˆ›å»º `monitor_gpu.sh`ï¼š

```bash
#!/bin/bash
# GPUç›‘æŽ§è„šæœ¬

echo "Monitoring GPU usage..."
echo "Press Ctrl+C to stop"
echo ""

while true; do
    clear
    date
    echo ""
    nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv
    echo ""
    echo "Training processes:"
    ps aux | grep python | grep main.py
    sleep 2
done
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# å‡å°batch size
# ç¼–è¾‘ config.yaml:
training:
  batch_size: 64  # ä»Ž256é™åˆ°64
```

### Q2: Mambaå®‰è£…å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install mamba-ssm --no-build-isolation

# æˆ–è·³è¿‡Mambaï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨GRUæ›¿ä»£
# æ— éœ€ä»»ä½•ä¿®æ”¹
```

### Q3: æ•°æ®ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ¡ˆ1: ä½¿ç”¨akshareï¼ˆå›½å†…æºï¼‰
# ä¿®æ”¹ config.yaml:
data:
  data_source: "akshare"

# æ–¹æ¡ˆ2: ä½¿ç”¨ä»£ç†
export http_proxy=http://proxy_address:port
export https_proxy=http://proxy_address:port
```

### Q4: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. ç¡®è®¤ä½¿ç”¨GPU
python -c "import torch; print(torch.cuda.is_available())"

# 2. å¢žå¤§batch size
# config.yaml:
training:
  batch_size: 256  # RTX 5090å¯ä»¥æ›´å¤§

# 3. å‡å°‘æ•°æ®é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
data:
  stock_codes: ["600519.SS"]  # åªç”¨1åªè‚¡ç¥¨
```

### Q5: è¿œç¨‹è®¿é—®å¯è§†åŒ–ç»“æžœ

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ¡ˆ1: ä½¿ç”¨Jupyter
pip install jupyter
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser

# æ–¹æ¡ˆ2: ä½¿ç”¨HTTPæœåŠ¡å™¨
cd plots
python -m http.server 8000
# è®¿é—®: http://[æœåŠ¡å™¨IP]:8000

# æ–¹æ¡ˆ3: ä¸‹è½½åˆ°æœ¬åœ°
scp -r user@server:/path/to/plots ./local_plots
```

---

## ðŸ“¦ Dockeréƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

### Dockerfile

```dockerfile
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

WORKDIR /workspace

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# å…‹éš†é¡¹ç›®
RUN git clone https://github.com/li147852xu/ARIN7101_Project_Stock_Prediction.git
WORKDIR /workspace/ARIN7101_Project_Stock_Prediction

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir yfinance akshare ta prophet statsmodels

# é…ç½®
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTHONUNBUFFERED=1

# å…¥å£ç‚¹
CMD ["python", "main.py"]
```

æž„å»ºå’Œè¿è¡Œï¼š

```bash
# æž„å»ºé•œåƒ
docker build -t stock-prediction:latest .

# è¿è¡Œå®¹å™¨
docker run --gpus all -v $(pwd)/results:/workspace/results stock-prediction:latest
```

---

## ðŸŽ¯ å®Œæ•´Demoæ£€æŸ¥æ¸…å•

è¿è¡ŒDemoå‰æ£€æŸ¥ï¼š

- [ ] GPUå¯ç”¨ (`nvidia-smi`)
- [ ] CUDAç‰ˆæœ¬æ­£ç¡® (`nvcc --version`)
- [ ] PythonçŽ¯å¢ƒå°±ç»ª (`python --version`)
- [ ] ä¾èµ–å·²å®‰è£… (`python test_setup.py`)
- [ ] ç½‘ç»œè¿žæŽ¥æ­£å¸¸ (ä¸‹è½½æ•°æ®ç”¨)
- [ ] ç£ç›˜ç©ºé—´å……è¶³ (è‡³å°‘10GB)

è¿è¡ŒDemoåŽéªŒè¯ï¼š

- [ ] æ•°æ®æˆåŠŸä¸‹è½½ (`data/raw/` æœ‰æ–‡ä»¶)
- [ ] æ¨¡åž‹è®­ç»ƒå®Œæˆ (`results/models/` æœ‰.pthæ–‡ä»¶)
- [ ] è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ (`results/` æœ‰CSVå’ŒTXT)
- [ ] å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ (`plots/` æœ‰PNGå›¾ç‰‡)
- [ ] æ—¥å¿—æ–‡ä»¶æ­£å¸¸ (`logs/` æœ‰æ—¥å¿—)

---

## ðŸ“ž æŠ€æœ¯æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**ï¼š`cat logs/*.log`
2. **æ£€æŸ¥GPU**ï¼š`nvidia-smi`
3. **æµ‹è¯•é…ç½®**ï¼š`python test_setup.py`
4. **æŸ¥çœ‹æ–‡æ¡£**ï¼šé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„å„ä¸ª.mdæ–‡ä»¶

---

## ðŸŽ‰ æ€»ç»“

æœ¬æ–¹æ¡ˆæä¾›äº†ä¸‰ç§Demoè¿è¡Œæ–¹å¼ï¼š

1. **å¿«é€Ÿæµ‹è¯•** (5åˆ†é’Ÿ) - éªŒè¯çŽ¯å¢ƒ
2. **æ ‡å‡†Demo** (20åˆ†é’Ÿ) - å¸¸è§„å±•ç¤º
3. **å®Œæ•´Demo** (60-90åˆ†é’Ÿ) - å®Œæ•´å®žéªŒ

é€‰æ‹©é€‚åˆä½ æ—¶é—´å’Œéœ€æ±‚çš„æ–¹æ¡ˆå³å¯ï¼

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åŽæ›´æ–°**: 2024-11-14  
**å¹³å°**: RTX 5090 / CUDA 12.1+  
**é¡¹ç›®åœ°å€**: https://github.com/li147852xu/ARIN7101_Project_Stock_Prediction

